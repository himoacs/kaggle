{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('kaggle-titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download train and test datasets from my github repo: https://github.com/himoacs/kaggle/tree/master/titanic\n",
    "# Upload them into databricks so you can easily load them into a DataFrame\n",
    "train_df = spark.read.format('csv').options(header='true', \n",
    "                                            inferSchema='true').load('/Users/himanshugupta/kaggle/titanic/train.csv')\n",
    "\n",
    "train_df.show()\n",
    "\n",
    "# Here is the description of each column provided by Kaggle\n",
    "# PassengerId - Unique id for the passenger\n",
    "# Survived - Whether the passenger survived or not\n",
    "# Pclass - Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "# Name - Passenger's name\n",
    "# Sex - Passenger's sex\n",
    "# Age - Passenger's age\n",
    "# SibSp - Number of siblings / spouses aboard the Titanic\n",
    "# Parch - Number of parents / children aboard the Titanic\n",
    "# Ticket - Ticket number\n",
    "# Fare - Ticket fare\n",
    "# Cabin - Cabin number\n",
    "# Embarked - Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also take a look at the schema\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to decide which of the features provided to us can actually be used to predict whether \n",
    "# a passenger survives or drowns. I am going to exclude PassengerId, Name, Parch, Ticket and Cabin \n",
    "# because these I don't believe these features influence the outcome. For example, whether a person \n",
    "# survives or not doesn't decide on his or her name. We can sometimes get additionall information from \n",
    "# these features such as extract the title and see if a person is a doctor or not and use that as a feature. \n",
    "# This technique is called Feature Engineering and we will not be focusing on that in thist post. Which features \n",
    "# you select is also a personal decision. You may think that number of children a passenger has on-board \n",
    "# might matter whereas I might think that it does not. While there are some very obvious features that should \n",
    "# be included, others can be tough to select.\n",
    "\n",
    "train_df = train_df.select(['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------+------------------+-----------------+--------+\n",
      "|summary|           Survived|            Pclass|   Sex|               Age|             Fare|Embarked|\n",
      "+-------+-------------------+------------------+------+------------------+-----------------+--------+\n",
      "|  count|                891|               891|   891|               714|              891|     889|\n",
      "|   mean| 0.3838383838383838| 2.308641975308642|  null| 29.69911764705882| 32.2042079685746|    null|\n",
      "| stddev|0.48659245426485753|0.8360712409770491|  null|14.526497332334035|49.69342859718089|    null|\n",
      "|    min|                  0|                 1|female|              0.42|              0.0|       C|\n",
      "|    max|                  1|                 3|  male|              80.0|         512.3292|       S|\n",
      "+-------+-------------------+------------------+------+------------------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's explore the dataset\n",
    "train_df.describe().show()\n",
    "\n",
    "# As we can see below, we have 891 rows for 4 columns but two columns (Age and Embarked) \n",
    "# have 714 and 889 values. This is because they have missing/NA values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "|summary|          Survived|            Pclass|   Sex|              Age|              Fare|Embarked|\n",
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "|  count|               712|               712|   712|              712|               712|     712|\n",
      "|   mean|0.4044943820224719| 2.240168539325843|  null|29.64209269662921| 34.56725140449432|    null|\n",
      "| stddev|0.4911389472541192|0.8368543166903446|  null|14.49293290032352|52.938648174710906|    null|\n",
      "|    min|                 0|                 1|female|             0.42|               0.0|       C|\n",
      "|    max|                 1|                 3|  male|             80.0|          512.3292|       S|\n",
      "+-------+------------------+------------------+------+-----------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's clean this data by dropping any rows with null values\n",
    "train_df_clean = train_df.na.drop()\n",
    "train_df_clean.describe().show()\n",
    "\n",
    "# As you can see now, after we drop the rows with null values, we have a total of 712 rows and \n",
    "# each column has the same number of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a feel of what the data looks like and have cleaned it up, we can start analyzing the data.\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have some categorical features (Sex and Embarked) in our dataset, we need to 'OneHotEncoder' \n",
    "# them so that our machine learning model can understand them. I have a separate post that explains \n",
    "# OneHotEncoding: http://www.enlistq.com/feature-encoding-python-using-scikit-learn/\n",
    "\n",
    "sex_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "sex_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')\n",
    "\n",
    "# We will need to do the same for our other categorical feature - Embarked.\n",
    "\n",
    "embarked_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedIndex')\n",
    "embarked_encoder = OneHotEncoder(inputCol='EmbarkedIndex', outputCol='EmbarkedVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our categorical features encoded, we are ready to convert our training dataset \n",
    "# into the vector form that Spark's MLlib expects it to be into. Remember to not include the 'Survived' \n",
    "# column as an input because that's what we are trying to predict.\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['Pclass', 'SexVec', 'Age', 'Fare', 'EmbarkedVec'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to use Logistic Regression model. I have covered Logistic Regression in my earlier \n",
    "# post: http://www.enlistq.com/implementing-a-binomial-logistic-regression-model-in-python/\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic_reg_model = LogisticRegression(featuresCol='features', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now create a pipeline to bring everything together.\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[sex_indexer, embarked_indexer, sex_encoder, embarked_encoder, \n",
    "                            assembler, logistic_reg_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now fit our logistic regression model on our training dataset\n",
    "model_fit = pipeline.fit(train_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "|summary|       PassengerId|            Pclass|   Sex|               Age|              Fare|Embarked|\n",
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "|  count|               418|               418|   418|               332|               417|     418|\n",
      "|   mean|            1100.5|2.2655502392344498|  null|30.272590361445783|  35.6271884892086|    null|\n",
      "| stddev|120.81045760473994|0.8418375519640503|  null|14.181209235624424|55.907576179973844|    null|\n",
      "|    min|               892|                 1|female|              0.17|               0.0|       C|\n",
      "|    max|              1309|                 3|  male|              76.0|          512.3292|       S|\n",
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# According to the Kaggle submission rules, we need to predict values for the passengers \n",
    "# listed in 'test.csv' and then submit those results to Kaggle.\n",
    "# The final results should include two columns: PassengerId and Survived.\n",
    "\n",
    "test_df = spark.read.format('csv').options(header='true', \n",
    "                                           inferSchema='true').load('/Users/himanshugupta/kaggle/titanic/test.csv')\n",
    "\n",
    "test_df = test_df.select(['PassengerId', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked'])\n",
    "test_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "|summary|       PassengerId|            Pclass|   Sex|               Age|              Fare|Embarked|\n",
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "|  count|               418|               418|   418|               418|               418|     418|\n",
      "|   mean|            1100.5|2.2655502392344498|  null|30.272590361445815|  35.6271884892086|    null|\n",
      "| stddev|120.81045760473994|0.8418375519640503|  null|12.634534168325061|55.840500479541056|    null|\n",
      "|    min|               892|                 1|female|              0.17|               0.0|       C|\n",
      "|    max|              1309|                 3|  male|              76.0|          512.3292|       S|\n",
      "+-------+------------------+------------------+------+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As we can see, some of the rows don't have Age and/or Fare. We need to fill these with some \n",
    "# sensible values. One popular way to fill missing values is to use the mean.\n",
    "\n",
    "age_mean = test_df.agg({'Age': 'mean'}).first()[0]\n",
    "fare_mean = test_df.agg({'Fare': 'mean'}).first()[0]\n",
    "test_df = test_df.fillna(age_mean, subset=['Age'])\n",
    "test_df = test_df.fillna(fare_mean, subset=['Fare'])\n",
    "\n",
    "# As we can see now, all columns have the same number of values (418)\n",
    "test_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to feed the test data to our fitted model and predict.\n",
    "results = model_fit.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|PassengerId|prediction|\n",
      "+-----------+----------+\n",
      "|        892|       0.0|\n",
      "|        893|       0.0|\n",
      "|        894|       0.0|\n",
      "|        895|       0.0|\n",
      "|        896|       1.0|\n",
      "|        897|       0.0|\n",
      "|        898|       0.0|\n",
      "|        899|       0.0|\n",
      "|        900|       1.0|\n",
      "|        901|       0.0|\n",
      "|        902|       0.0|\n",
      "|        903|       0.0|\n",
      "|        904|       1.0|\n",
      "|        905|       0.0|\n",
      "|        906|       1.0|\n",
      "|        907|       1.0|\n",
      "|        908|       0.0|\n",
      "|        909|       0.0|\n",
      "|        910|       1.0|\n",
      "|        911|       1.0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here is what our predictions look like:\n",
    "kaggle_results = results.select('PassengerId', 'prediction')\n",
    "kaggle_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV so we can submit to Kaggle\n",
    "import pandas as pd\n",
    "kaggle_results.toPandas().to_csv(r'/Users/himanshugupta/kaggle/titanic/titanic_kaggle_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
